{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lower Triangular Matrix Vector Multiply Routines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks you through how to implement $ x := L x $ where $ L $ is lower triangular.  Vector $ y $ is not to be touched (and, indeed, not even passed into the routines).  This is a little trickier than you might think.  Order matters, since you don't want to corrupt values of $ x $ that are still needed.  Indeed, you may want to do a few small problems by hand if you don't get the right answer.  Also, PictureFLAME may help you see what is going on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use some functions that are part of our laff library (of which this function will become a part) as well as some routines from the FLAME API (Application Programming Interface) that allows us to write code that closely resembles how we typeset algorithms using the FLAME notation.  These functions are imported with `include` and `using` statements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm that takes dot products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `Trmv_ln_unb_var1!( L, x )`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This routine, given lower triangular $ L \\in \\mathbb{R}^{n \\times n} $ and $ x \\in \\mathbb{R}^n $ computes $ x := L x $.  The \"_un_\" in the name of the routine indicates this is the \"lower, no transpose\" matrix-vector multiplication.  \n",
    "\n",
    "The specific laff functions we will use are \n",
    "<ul>\n",
    "<li> <code> laff.dots!( x, y, alpha ) </code> which computes $ \\alpha := x^T y + \\alpha $.  </li>\n",
    "<li> <code> laff.scal!( alpha, x ) </code> which computes $ x := \\alpha x $.  </li> (You will want to use this one to update $ \\chi_1 $ if you want to use PictureFrame.)\n",
    "</ul>\n",
    "\n",
    "Use the <a href=\"https://studio.edx.org/c4x/UTAustinX/UT.5.01x/asset/index.html\"> Spark webpage</a> to generate a code skeleton.  (Make sure you adjust the name of the routine.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <font color=red> NOTE: The algorithms for this operation march from bottom-right to top-left!!! </font> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trmv_ln_unb_var1! (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"../flame.jl\")\n",
    "using .flame\n",
    "include(\"../laff/laff.jl\")\n",
    "using .laff\n",
    "\n",
    "function Trmv_ln_unb_var1!(L, x)\n",
    "\n",
    "    LTL, LTR, \n",
    "    LBL, LBR  = flame.part_2x2(L, \n",
    "                               0, 0, \"BR\")\n",
    "\n",
    "    xT, \n",
    "    xB  = flame.part_2x1(x, \n",
    "                         0, \"BOTTOM\")\n",
    "\n",
    "    while size(LBR, 1) < size(L, 1)\n",
    "\n",
    "        L00,  l01,      L02,  \n",
    "        l10t, lambda11, l12t, \n",
    "        L20,  l21,      L22   = flame.repart_2x2_to_3x3(LTL, LTR, \n",
    "                                                        LBL, LBR, \n",
    "                                                        1, 1, \"TL\")\n",
    "\n",
    "        x0,   \n",
    "        chi1, \n",
    "        x2    = flame.repart_2x1_to_3x1(xT, \n",
    "                                        xB, \n",
    "                                        1, \"TOP\")\n",
    "\n",
    "        #------------------------------------------------------------#\n",
    "\n",
    "        laff.scal!( lambda11, chi1 )\n",
    "        laff.dots!( l10t, x0, chi1 )\n",
    "\n",
    "        #------------------------------------------------------------#\n",
    "\n",
    "        LTL, LTR, \n",
    "        LBL, LBR  = flame.cont_with_3x3_to_2x2(L00,  l01,      L02,  \n",
    "                                               l10t, lambda11, l12t, \n",
    "                                               L20,  l21,      L22,  \n",
    "                                               \"BR\")\n",
    "\n",
    "        xT, \n",
    "        xB  = flame.cont_with_3x1_to_2x1(x0,   \n",
    "                                         chi1, \n",
    "                                         x2,   \n",
    "                                         \"BOTTOM\")\n",
    "\n",
    "    end\n",
    "\n",
    "    flame.merge_2x1!(xT, \n",
    "                     xB, x)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly test the routine by creating a 4 x 4 matrix and related vectors, performing the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L before =\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4Ã—4 Array{Float64,2}:\n",
       " 0.537314   0.580936  0.101353   0.00630569\n",
       " 0.360352   0.281655  0.0742317  0.948244  \n",
       " 0.0782696  0.259455  0.406168   0.312105  \n",
       " 0.694981   0.729     0.0318094  0.647208  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = rand(4, 4)\n",
    "x = rand(4)\n",
    "xold = rand(4)\n",
    "laff.copy!(x, xold)\n",
    "\n",
    "# Notice that L is not lower triangular.  We will only use the lower triangular part.\n",
    "\n",
    "println( \"L before =\" )\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x before =\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.8934808881309593 \n",
       " 0.5682685705921706 \n",
       " 0.6671068071894872 \n",
       " 0.37423563646800306"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println( \"x before =\" )\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x after =\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.48007959814861684\n",
       " 0.48202319163423946\n",
       " 0.48832953813085955\n",
       " 1.298648643813022  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trmv_ln_unb_var1!( L, x )\n",
    "\n",
    "println( \"x after =\" )\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.48007959814861684\n",
       " 0.48202319163423946\n",
       " 0.4883295381308595 \n",
       " 1.298648643813022  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "LowerTriangular( L ) * xold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x - ( LowerTriangular( L ) * xold ) = \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.0                  \n",
       " 0.0                  \n",
       " 5.551115123125783e-17\n",
       " 0.0                  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println( \"x - ( LowerTriangular( L ) * xold ) = \" ) # LowerTriangular() makes a matrix lower triangular\n",
    "x - ( LowerTriangular( L ) * xold ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bingo, it seems to work!  (Notice that we are doing floating point computations, which means that due to rounding you may not get an exact \"0\".)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watch your code in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy and paste the code into <a href=\"http://edx-org-utaustinx.s3.amazonaws.com/UT501x/PictureFlame/PictureFLAME.html\"> PictureFLAME </a>, a webpage where you can watch your routine in action.  Just cut and paste into the box.  \n",
    "\n",
    "Disclaimer: we implemented a VERY simple interpreter.  If you do something wrong, we cannot guarantee the results.  But if you do it right, you are in for a treat.\n",
    "\n",
    "If you want to reset the problem, just click in the box into which you pasted the code and hit \"next\" again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm that uses axpys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `Trmv_ln_unb_var2!( L, x )` routine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This routine, given lower triangular $ L \\in \\mathbb{R}^{n \\times n} $ and $ x \\in \\mathbb{R}^n $ computes $ x := L x $.  The \"_ln_\" in the name of the routine indicates this is the \"lower triangular, no transpose\" matrix-vector multiplication.  \n",
    "\n",
    "The specific laff functions we will use are \n",
    "<ul>\n",
    "<li> <code> laff.axpy!( alpha, x, y ) </code> which computes $ y := \\alpha x +  y  $.  </li>\n",
    "<li> <code> laff.scal!( alpha, x ) </code> which computes $ x := \\alpha x $.  </li> (You will want to use this one to update $ \\chi_1 $ if you want to use PictureFrame.)\n",
    "</ul>\n",
    "\n",
    "Use the <a href=\"https://studio.edx.org/c4x/UTAustinX/UT.5.01x/asset/index.html\"> Spark webpage</a> to generate a code skeleton.  (Make sure you adjust the name of the routine.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module flame.\n",
      "WARNING: replacing module laff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Trmv_ln_unb_var2! (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"../flame.jl\")\n",
    "using .flame\n",
    "include(\"../laff/laff.jl\")\n",
    "using .laff\n",
    "\n",
    "function Trmv_ln_unb_var2!(L, x)\n",
    "\n",
    "    LTL, LTR, \n",
    "    LBL, LBR  = flame.part_2x2(L, \n",
    "                               0, 0, \"BR\")\n",
    "\n",
    "    xT, \n",
    "    xB  = flame.part_2x1(x, \n",
    "                         0, \"BOTTOM\")\n",
    "\n",
    "    while size(LBR, 1) < size(L, 1)\n",
    "\n",
    "        L00,  l01,      L02,  \n",
    "        l10t, lambda11, l12t, \n",
    "        L20,  l21,      L22   = flame.repart_2x2_to_3x3(LTL, LTR, \n",
    "                                                        LBL, LBR, \n",
    "                                                        1, 1, \"TL\")\n",
    "\n",
    "        x0,   \n",
    "        chi1, \n",
    "        x2    = flame.repart_2x1_to_3x1(xT, \n",
    "                                        xB, \n",
    "                                        1, \"TOP\")\n",
    "\n",
    "        #------------------------------------------------------------#\n",
    "\n",
    "        laff.axpy!( chi1, l21, x2 )\n",
    "        laff.scal!( lambda11, chi1 )\n",
    "\n",
    "        #------------------------------------------------------------#\n",
    "\n",
    "        LTL, LTR, \n",
    "        LBL, LBR  = flame.cont_with_3x3_to_2x2(L00,  l01,      L02,  \n",
    "                                               l10t, lambda11, l12t, \n",
    "                                               L20,  l21,      L22,  \n",
    "                                               \"BR\")\n",
    "\n",
    "        xT, \n",
    "        xB  = flame.cont_with_3x1_to_2x1(x0,   \n",
    "                                         chi1, \n",
    "                                         x2,   \n",
    "                                         \"BOTTOM\")\n",
    "\n",
    "    end\n",
    "\n",
    "    flame.merge_2x1!(xT, \n",
    "                     xB, x)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly test the routine by creating a 4 x 4 matrix and related vectors, performing the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L before =\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4Ã—4 Array{Float64,2}:\n",
       " 0.263821   0.625739   0.0469045  0.684802\n",
       " 0.0746397  0.964173   0.2556     0.310802\n",
       " 0.703699   0.0555006  0.275488   0.795835\n",
       " 0.256547   0.965193   0.171865   0.771629"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = rand(4, 4)\n",
    "x = rand(4)\n",
    "xold = rand(4)\n",
    "laff.copy!(x, xold)\n",
    "\n",
    "# Notice that L is not lower triangular.  We will only use the lower triangular part.\n",
    "\n",
    "println( \"L before =\" )\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x before =\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.20532106890358626\n",
       " 0.4590191228147402 \n",
       " 0.13517161004176637\n",
       " 0.0979460470541198 "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println( \"x before =\" )\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x after =\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.0541680924273256 \n",
       " 0.45789908142175906\n",
       " 0.20719817446388616\n",
       " 0.5945258309973844 "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trmv_ln_unb_var2!( L, x )\n",
    "\n",
    "println( \"x after =\" )\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.0541680924273256 \n",
       " 0.45789908142175906\n",
       " 0.20719817446388616\n",
       " 0.5945258309973844 "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "LowerTriangular( L ) * xold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x - ( LowerTriangular( L ) * xold ) = \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println( \"x - ( LowerTriangular( L ) * xold ) = \" ) # LowerTriangular() makes a matrix lower triangular\n",
    "x - ( LowerTriangular( L ) * xold ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bingo, it seems to work!  (Notice that we are doing floating point computations, which means that due to rounding you may not get an exact \"0\".)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watch your code in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy and paste the code into <a href=\"http://edx-org-utaustinx.s3.amazonaws.com/UT501x/PictureFlame/PictureFLAME.html\"> PictureFLAME </a>, a webpage where you can watch your routine in action.  Just cut and paste into the box.  \n",
    "\n",
    "Disclaimer: we implemented a VERY simple interpreter.  If you do something wrong, we cannot guarantee the results.  But if you do it right, you are in for a treat.\n",
    "\n",
    "If you want to reset the problem, just click in the box into which you pasted the code and hit \"next\" again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.1",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
