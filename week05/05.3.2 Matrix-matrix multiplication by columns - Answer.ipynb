{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix-matrix multiplication by columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look at how the FLAMEJulia API can be used to implement different matrix-matrix multiplication algorithms.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create some matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4×3 Array{Float64,2}:\n",
       " 0.74971    0.745538  0.090947\n",
       " 0.910935   0.248869  0.720639\n",
       " 0.597413   0.664635  0.166778\n",
       " 0.0949942  0.592252  0.724036"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 4\n",
    "n = 3\n",
    "k = 5\n",
    "\n",
    "C = rand(m, n)\n",
    "println( \"C = \")\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4×5 Array{Float64,2}:\n",
       " 0.637571  0.696629  0.217307  0.127578  0.102013\n",
       " 0.622843  0.945459  0.899098  0.390123  0.484672\n",
       " 0.266225  0.18644   0.171075  0.517504  0.726257\n",
       " 0.967062  0.9392    0.912189  0.237931  0.47508 "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cold = copy(C)          # an alternative way of doing a \"hard\" copy, in this case of a matrix\n",
    "    \n",
    "A = rand(m, k)\n",
    "println(\"A = \" )\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B = \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5×3 Array{Float64,2}:\n",
       " 0.782818  0.845178  0.784613\n",
       " 0.268421  0.649096  0.507649\n",
       " 0.992778  0.633345  0.278936\n",
       " 0.383018  0.234097  0.86429 \n",
       " 0.750724  0.243729  0.833391"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = rand(k, n)\n",
    "println( \"B = \" )\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h2>The algorithm  </h2>  \n",
    "\n",
    "<img src=\"https://studio.edx.org/c4x/UTAustinX/UT.5.01x/asset/Gemm_nn_unb_var1.png\" alt=\"Matrix-matrix multiplication by columns picture\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> The routine <code> Gemm_nn_unb_var1!( A, B, C ) </code> </h2>\n",
    "\n",
    "This routine computes $ C := A B + C $ by columns.  The \"\\_nn\\_\" means that this is the \"No transpose, No transpose\" case of matrix multiplication.  \n",
    "The reason for this is that the operations $ C := A^T B + C $ (\"\\_tn\\_\" or \"Transpose, No transpose\"), $ C := A B^T + C $ (\"\\_nt\\_\" or \"No transpose, Transpose\"), and $ C := A^T B^T + C $ (\"\\_tt\\_\" or \"Transpose, Transpose\") are also encountered.  \n",
    "    \n",
    "The specific laff function we will use is\n",
    "<ul>\n",
    "<li> <code> laff.gemv!( trans, alpha, A, x, beta, y ) </code> which computes \n",
    "$ y := \\alpha A x + \\beta y $ or $ y := \\alpha A^T x + \\beta y $, depending on \n",
    "        parameter <code> trans</code>.  In particular, \n",
    "        <ul>\n",
    "        <li>\n",
    "        <code> laff.gemv!( \"No transpose\", alpha, A, x, beta, y ) </code> computes $ y := \\alpha A x + \\beta y $.\n",
    "            </li>\n",
    "        <li>\n",
    "        <code> laff.gemv!( \"Transpose\", alpha, A, x, beta, y ) </code> computes $ y := \\alpha A^T x + \\beta y $.\n",
    "            </li>\n",
    "            </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "Use the <a href=\"https://studio.edx.org/c4x/UTAustinX/UT.5.01x/asset/index.html\"> Spark webpage</a> to generate a code skeleton.  (Make sure you adjust the name of the routine.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module flame.\n",
      "WARNING: replacing module laff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Gemm_nn_unb_var1! (generic function with 1 method)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"../flame.jl\")\n",
    "using .flame\n",
    "include(\"../laff/laff.jl\")\n",
    "using .laff\n",
    "\n",
    "function Gemm_nn_unb_var1!(A, B, C)\n",
    "\n",
    "    BL, BR = flame.part_1x2(B, \n",
    "                            0, \"LEFT\")\n",
    "\n",
    "    CL, CR = flame.part_1x2(C, \n",
    "                            0, \"LEFT\")\n",
    "\n",
    "    while size(BL, 2) < size(B, 2)\n",
    "\n",
    "        B0, b1, B2 = flame.repart_1x2_to_1x3(BL, BR, \n",
    "                                             1, \"RIGHT\")\n",
    "\n",
    "        C0, c1, C2 = flame.repart_1x2_to_1x3(CL, CR, \n",
    "                                             1, \"RIGHT\")\n",
    "\n",
    "        #------------------------------------------------------------#\n",
    "\n",
    "        laff.gemv!( \"No transpose\", 1.0, A, b1, 1.0, c1 )\n",
    "\n",
    "        #------------------------------------------------------------#\n",
    "\n",
    "        BL, BR = flame.cont_with_1x3_to_1x2(B0, b1, B2, \n",
    "                                            \"LEFT\")\n",
    "\n",
    "        CL, CR = flame.cont_with_1x3_to_1x2(C0, c1, C2, \n",
    "                                            \"LEFT\")\n",
    "\n",
    "    end\n",
    "\n",
    "    flame.merge_1x2!(CL, CR, C)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C - ( Cold + A * B )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4×3 Array{Float64,2}:\n",
       " 0.0  0.0  0.0\n",
       " 0.0  0.0  0.0\n",
       " 0.0  0.0  0.0\n",
       " 0.0  0.0  0.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = copy( Cold ) # restore C \n",
    "\n",
    "Gemm_nn_unb_var1!( A, B, C )\n",
    "\n",
    "println( \"C - ( Cold + A * B )\" )\n",
    "C - ( Cold + A * B )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bingo! It works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watch the algorithm at work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy and paste the code into <a href=\"http://edx-org-utaustinx.s3.amazonaws.com/UT501x/PictureFlame/PictureFLAME.html\"> PictureFLAME </a>, a webpage where you can watch your routine in action.  Just cut and paste into the box.  \n",
    "\n",
    "Disclaimer: we implemented a VERY simple interpreter.  If you do something wrong, we cannot guarantee the results.  But if you do it right, you are in for a treat.\n",
    "\n",
    "If you want to reset the problem, just click in the box into which you pasted the code and hit \"next\" again."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.1",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
