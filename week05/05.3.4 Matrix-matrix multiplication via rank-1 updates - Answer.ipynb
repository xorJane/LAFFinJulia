{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix-matrix multiplication via rank-1 updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue to look at how the FLAMEJulia API can be used to implement different matrix-matrix multiplication algorithms.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create some matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4×3 Array{Float64,2}:\n",
       " 0.523918  0.907567  0.129295 \n",
       " 0.636291  0.976137  0.0390747\n",
       " 0.64707   0.838093  0.933974 \n",
       " 0.839264  0.478611  0.659468 "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 4\n",
    "n = 3\n",
    "k = 5\n",
    "\n",
    "C = rand(m, n)\n",
    "println( \"C = \")\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4×5 Array{Float64,2}:\n",
       " 0.894742  0.0650961  0.858902  0.567061  0.0937017\n",
       " 0.13064   0.880969   0.231842  0.754032  0.485299 \n",
       " 0.604483  0.740901   0.103469  0.768992  0.361006 \n",
       " 0.660144  0.246472   0.679104  0.512128  0.753729 "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cold = copy( C ) # an alternative way of doing a \"hard\" copy, in this case of a matrix\n",
    "    \n",
    "A = rand(m, k)\n",
    "println( \"A = \" )\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B = \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5×3 Array{Float64,2}:\n",
       " 0.514185  0.762752   0.394554\n",
       " 0.816862  0.35512    0.914569\n",
       " 0.710208  0.0968876  0.443689\n",
       " 0.350955  0.840034   0.508605\n",
       " 0.942621  0.572481   0.900676"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = rand(k, n)\n",
    "println( \"B = \" )\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h2>The algorithm  </h2>  <image src=\"https://studio.edx.org/c4x/UTAustinX/UT.5.01x/asset/Gemm_nn_unb_var3.png\" alt=\"Matrix-matrix multiplication via rank-1 updates picture\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> The routine <code> Gemm_nn_unb_var3( A, B, C ) </code> </h2>\n",
    "\n",
    "This routine computes $ C := A B + C $ via rank-1 updates.  The \"\\_nn\\_\" means that this is the \"No transpose, No transpose\" case of matrix multiplication.  \n",
    "The reason for this is that the operations $ C := A^T B + C $ (\"\\_tn\\_\" or \"Transpose, No transpose\"), $ C := A B^T + C $ (\"\\_nt\\_\" or \"No transpose, Transpose\"), and $ C := A^T B^T + C $ (\"\\_tt\\_\" or \"Transpose, Transpose\") are also encountered.  \n",
    "    \n",
    "The specific laff function we will use is\n",
    "<ul>\n",
    "<li> <code> laff.ger!( alpha, x, y, A ) </code> which computes the rank-1 update (adds a multiple of an outer product to a matrix)\n",
    "$ A := \\alpha x y^T + A $. \n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "Use the <a href=\"https://studio.edx.org/c4x/UTAustinX/UT.5.01x/asset/index.html\"> Spark webpage</a> to generate a code skeleton.  (Make sure you adjust the name of the routine.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gemm_nn_unb_var3! (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"../flame.jl\")\n",
    "using .flame\n",
    "include(\"../laff/laff.jl\")\n",
    "using .laff\n",
    "\n",
    "function Gemm_nn_unb_var3!(A, B, C)\n",
    "\n",
    "    AL, AR = flame.part_1x2(A, \n",
    "                            0, \"LEFT\")\n",
    "\n",
    "    BT, \n",
    "    BB  = flame.part_2x1(B, \n",
    "                         0, \"TOP\")\n",
    "\n",
    "    while size(AL, 2) < size(A, 2)\n",
    "\n",
    "        A0, a1, A2 = flame.repart_1x2_to_1x3(AL, AR, \n",
    "                                             1, \"RIGHT\")\n",
    "\n",
    "        B0,  \n",
    "        b1t, \n",
    "        B2   = flame.repart_2x1_to_3x1(BT, \n",
    "                                       BB, \n",
    "                                       1, \"BOTTOM\")\n",
    "\n",
    "        #------------------------------------------------------------#\n",
    "\n",
    "        laff.ger!( 1.0, a1, b1t, C )\n",
    "\n",
    "        #------------------------------------------------------------#\n",
    "\n",
    "        AL, AR = flame.cont_with_1x3_to_1x2(A0, a1, A2, \n",
    "                                            \"LEFT\")\n",
    "\n",
    "        BT, \n",
    "        BB  = flame.cont_with_3x1_to_2x1(B0,  \n",
    "                                         b1t, \n",
    "                                         B2,  \n",
    "                                         \"TOP\")\n",
    "\n",
    "    end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C - ( Cold + A * B )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4×3 Array{Float64,2}:\n",
       " 0.0  -4.44089e-16   0.0        \n",
       " 0.0   0.0           2.22045e-16\n",
       " 0.0  -4.44089e-16  -4.44089e-16\n",
       " 0.0  -2.22045e-16   0.0        "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = copy( Cold ) # restore C \n",
    "\n",
    "Gemm_nn_unb_var3!( A, B, C )\n",
    "\n",
    "println( \"C - ( Cold + A * B )\" )\n",
    "C - ( Cold + A * B )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bingo! It works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watch the algorithm at work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy and paste the code into <a href=\"http://edx-org-utaustinx.s3.amazonaws.com/UT501x/PictureFlame/PictureFLAME.html\"> PictureFLAME </a>, a webpage where you can watch your routine in action.  Just cut and paste into the box.  \n",
    "\n",
    "Disclaimer: we implemented a VERY simple interpreter.  If you do something wrong, we cannot guarantee the results.  But if you do it right, you are in for a treat.\n",
    "\n",
    "If you want to reset the problem, just click in the box into which you pasted the code and hit \"next\" again."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.1",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
